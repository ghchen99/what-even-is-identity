# Biometric Unlock API Documentation

## Overview

This FastAPI backend provides biometric authentication using face and voice recognition. It uses local folder storage to mock Redis and PostgreSQL databases for development purposes.

## Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ endpoints/
â”‚   â”‚   â”‚   â”œâ”€â”€ biometric.py    # Enrollment & verification endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ users.py        # User management endpoints
â”‚   â”‚   â”‚   â””â”€â”€ health.py       # Health check endpoints
â”‚   â”‚   â””â”€â”€ routes.py           # API router configuration
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py           # Application configuration
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ user.py             # Data models
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â””â”€â”€ biometric.py        # Pydantic schemas
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ biometric.py        # ONNX model inference
â”‚   â”‚   â””â”€â”€ storage.py          # File-based storage
â”‚   â””â”€â”€ main.py                 # FastAPI app creation
â”œâ”€â”€ data/                       # Local storage (mock databases)
â”œâ”€â”€ models/                     # ONNX model files
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run.py                      # Server startup script
â””â”€â”€ .env.example               # Environment configuration
```

## Quick Start

1. Navigate to backend directory:
```bash
cd backend
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Copy and configure environment:
```bash
cp .env.example .env
# Edit .env file as needed
```

4. Start the server:
```bash
python run.py
```

5. Access the API documentation:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## API Endpoints

### Core Endpoints

#### `POST /api/v1/biometric/enroll`
Enroll a new user with face and voice biometrics.

**Parameters:**
- `user_id` (form): Unique identifier for the user
- `face_image` (file): Face image (JPEG/PNG)
- `voice_audio` (file): Voice audio sample

**Response:**
```json
{
  "status": "success",
  "enrollment_id": "uuid-string",
  "message": "User user123 enrolled successfully",
  "user_id": "user123"
}
```

#### `POST /api/v1/biometric/verify`
Verify a user's identity using face and voice biometrics.

**Parameters:**
- `user_id` (form): User identifier
- `face_image` (file): Face image for verification
- `voice_audio` (file): Voice audio for verification
- `threshold` (form, optional): Similarity threshold (default: 0.8)

**Response:**
```json
{
  "status": "success",
  "verified": true,
  "face_similarity": 0.92,
  "voice_similarity": 0.87,
  "combined_score": 0.90,
  "threshold": 0.8,
  "verification_id": "uuid-string"
}
```

### User Management

#### `GET /api/v1/users/{user_id}/enrollments`
Get all enrollments for a user.

#### `GET /api/v1/users/{user_id}/verifications`
Get recent verification attempts for a user.

**Query Parameters:**
- `limit` (optional): Number of recent verifications to return (default: 10)

#### `DELETE /api/v1/users/{user_id}`
Delete all data for a user.

### System Endpoints

#### `GET /api/v1/health`
Health check endpoint with model status.

#### `GET /api/v1/health/models`
Get detailed information about loaded ONNX models.

#### `POST /api/v1/health/cache/cleanup`
Clean up expired cache entries.

## Data Storage Structure

The system uses local folders to mock cloud databases:

```
backend/data/
â”œâ”€â”€ users/              # Mock PostgreSQL - User enrollments
â”‚   â”œâ”€â”€ user123.json
â”‚   â””â”€â”€ user456.json
â”œâ”€â”€ verifications/      # Mock PostgreSQL - Verification history
â”‚   â”œâ”€â”€ user123_verifications.json
â”‚   â””â”€â”€ user456_verifications.json
â””â”€â”€ cache/             # Mock Redis - Temporary cache
    â”œâ”€â”€ temp_key1.json
    â””â”€â”€ temp_key2.json
```

## ONNX Models

Place your ONNX models in the `backend/models/` directory:

- `backend/models/facenet.onnx` - Face recognition model (FaceNet)
- `backend/models/xvector.onnx` - Voice recognition model (x-vector)

When models are not available, the system uses mock embeddings for testing.

## Model Requirements

### Face Model (FaceNet)
- Input: RGB image, 160x160 pixels
- Expected format: NCHW (batch, channels, height, width)
- Normalization: [-1, 1] range
- Output: 512-dimensional embedding

### Voice Model (x-vector)
- Input: Audio features (MFCC or raw audio)
- Expected sample rate: 16kHz
- Output: 256-dimensional embedding

## Similarity Scoring

The system uses cosine similarity to compare embeddings:

- **Face Weight**: 60% of final score
- **Voice Weight**: 40% of final score
- **Combined Score**: Weighted average of face and voice similarities
- **Verification**: Pass if combined score â‰¥ threshold

## Security Considerations

1. **Data Storage**: All biometric data is stored locally
2. **Embeddings Only**: Raw biometric data is processed immediately and not stored
3. **Configurable Thresholds**: Adjust security vs usability
4. **No Network Storage**: All data remains on local machine

## Testing Without Models

The system includes mock embeddings when ONNX models are not available:

- Mock face embeddings: 512-dimensional random vectors
- Mock voice embeddings: 256-dimensional random vectors
- Consistent similarity calculations for testing

## Example Usage

### Enroll a User
```bash
curl -X POST "http://localhost:8000/api/v1/biometric/enroll" \
  -F "user_id=john_doe" \
  -F "face_image=@face.jpg" \
  -F "voice_audio=@voice.wav"
```

### Verify a User
```bash
curl -X POST "http://localhost:8000/api/v1/biometric/verify" \
  -F "user_id=john_doe" \
  -F "face_image=@face_verify.jpg" \
  -F "voice_audio=@voice_verify.wav" \
  -F "threshold=0.85"
```

### Check Health
```bash
curl "http://localhost:8000/api/v1/health"
```

## Debug Mode

The system includes a debug mode for face detection analysis. Enable it by setting the environment variable:

```bash
export BIOMETRIC_DEBUG=true
```

### Debug Output

When debug mode is enabled, the system saves visualization images to `debug_output/` directory:

#### Debug Image Types

1. **Detection Images** (`*_detected_*.jpg`):
   - **Red Box**: MediaPipe face detection bounding box
   - **Green Box**: Final crop area (detection + 20px margin)
   - **Text Label**: Detection confidence score
   - Shows the original image with overlaid detection results

2. **Cropped Images** (`*_cropped.jpg`):
   - The actual face region sent to the recognition model
   - Resized to 160x160 pixels (FaceNet standard)
   - Final processed image after detection and cropping

3. **Fallback Images** (`*_fallback_*.jpg`, `*_no_face_*.jpg`, `*_error_*.jpg`):
   - **Green Box**: Center crop area (70% of image)
   - Used when MediaPipe detection fails
   - Shows fallback cropping strategy

#### Debug Prefixes

- `enroll_<user_id>_*`: Images from enrollment process
- `verify_<user_id>_*`: Images from verification process
- `debug_test_*`: Images from manual testing

### Console Output

Debug mode also provides detailed console logging:

```
âœ… Face detected with confidence: 0.939
   Detection box: (928, 1630, 1735, 2437)
   Crop box (with margin): (908, 1610, 1755, 2457)
ğŸ› Debug image saved: debug_output/enroll_user123_detected_f8d111b4.jpg
```

This helps verify face detection accuracy and troubleshoot processing issues.

## Error Handling

The API returns appropriate HTTP status codes:

- `200`: Success
- `404`: User not found
- `422`: Validation error (invalid input)
- `500`: Internal server error

Error responses include detailed messages for debugging.